\documentclass[11pt]{article}
\usepackage[margin=0.6in]{geometry}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{titlesec}
\usepackage{array}
\pagestyle{empty}

\titleformat{\section}{\large\bfseries\uppercase}{}{0em}{}[\titlerule]
\titlespacing{\section}{0pt}{8pt}{4pt}

\begin{document}

\begin{center}
\textbf{\Large Aryasomayajula Ram Bharadwaj} \\
\vspace{4pt}
Bengaluru, India | \href{mailto:ram.bharadwaj.arya@gmail.com}{ram.bharadwaj.arya@gmail.com} | +91-9108832338 | \href{https://github.com/rokosbasilisk}{github.com/rokosbasilisk}
\end{center}

\vspace{12pt}

\section{Profile}
AI Engineer with six years of experience designing scalable AI systems and agentic workflows that bridge deep learning research and production deployment. Skilled in building LLM evaluation pipelines, developing interpretability experiments, and engineering infrastructure for reliable model reasoning and analysis. Published research on model compression, reasoning efficiency. Known for combining rigorous experimentation with strong systems design to advance trustworthy AI.

\section{Core Competencies}
\begin{itemize}[leftmargin=*,nosep]
\item \textbf{Research:} LLM evaluation, interpretability
\item \textbf{Frameworks:} PyTorch, JAX, Transformers, LangGraph, AutoGen
\item \textbf{Systems:} Docker, Kubernetes, Redis, Kafka, PostgreSQL, Microservices
\item \textbf{Cloud:} AWS, GCP
\item \textbf{Languages:} Python, Scala, Java
\end{itemize}

\section{Professional Experience}

\textbf{Associate Technical Architect} \hfill \textbf{Nov 2024 – Present}\\
\textit{Quantiphi Analytics, Bengaluru}
\begin{itemize}[leftmargin=*,nosep]
\item Designed AI agent system for automated issue-severity classification and escalation management.
\item Architected and implemented a conversational AI chatbot for a telecom client using LangGraph, improving modularity and reducing response latency by 3×.
\item Revamped the RAG ingestion pipeline to improve retrieval accuracy by 20\% and ensure consistent evaluation performance.
\end{itemize}

\textbf{AI Resident – Lossfunk AI Residency} \hfill \textbf{May 2025}\\
\textit{Lossfunk Research Residency}
\begin{itemize}[leftmargin=*,nosep]
\item Selected among 100+ applicants for a 6-week research program in interpretability and evaluation.
\item Developed redundancy-aware steering techniques (\href{https://arxiv.org/abs/2506.18831}{STU-PID}) achieving 32\% token reduction and higher reasoning accuracy on GSM8K.

\end{itemize}

\textbf{ML Engineer – Innovation \& Development Labs} \hfill \textbf{Jun 2019 – Nov 2024}\\
\textit{MuSigma Business Solutions, Bengaluru}
\begin{itemize}[leftmargin=*,nosep]
\item Led development of high-impact systems in LLM operationalization, automated trading, and scalable MLOps.
\item Migrated trading infrastructure from bare-metal to Kubernetes with automated hyperparameter search for ARIMA models.
\item Rebuilt trade-signal generation from R to Scala (Akka), enabling real-time analytics and adaptive portfolio retraining.
\item Designed ML model deployment microservices with CI/CD, blue-green, and canary rollout strategies.
\end{itemize}

\section{Highlighted Project}
\textbf{\href{https://wiserank.io}{Wiserank.io – AI-Powered Research Discovery}} \hfill \textbf{Jun 2025 – Present}\\
\textit{Creator \& Full-Stack Developer}
\begin{itemize}[leftmargin=*,nosep]
\item Built an AI-powered research discovery engine ranking papers by originality and information density.
\item Designed full-stack architecture with semantic search, citation generation.
\item Reached 100+ active research users within initial launch period.
\end{itemize}

\newpage
\section{Key Projects}
\textbf{Conversational Sales Chatbot using AI Agents} \hfill \textbf{2024 – Present}\\
\begin{itemize}[leftmargin=*,nosep]
\item Built agentic chatbot handling telecom sales queries using LangGraph.
\item Refactored proprietary workflow engine to modular pipelines, cutting code size by 40\%.
\end{itemize}

\textbf{LLM Agent Platform} \hfill \textbf{2023–2024}\\
\begin{itemize}[leftmargin=*,nosep]
\item Designed semi-autonomous data-analysis platform with automated prompt optimization and evaluation metrics.
\item Integrated RAG-based reasoning and ensemble evaluation for local LLM deployments.
\end{itemize}

\textbf{High-Velocity Trading Platform} \hfill \textbf{2021–2023}\\
\begin{itemize}[leftmargin=*,nosep]
\item Migrated backend architecture and integrated near real-time analytics using Akka and Scala.
\item Added retraining and visualization modules for portfolio metrics and latency diagnostics.
\end{itemize}

\textbf{ML Model Operationalization Platform} \hfill \textbf{2019–2021}\\
\begin{itemize}[leftmargin=*,nosep]
\item Automated retraining workflows for image models with multi-environment deployment via CI/CD.
\item Developed APIs for model serving and notebook-based microservice integration.
\end{itemize}

\section{Research \& Publications}
\textbf{\href{https://fullwrong.com/2025/07/23/scaling-compression/}{Scaling Laws for LLM-Based Data Compression}} \hfill \textbf{Jul 2025}\\
\textit{Lead Investigator} — Discovered scaling laws linking language model's capacity to compression efficiency across modalities.

\textbf{\href{https://arxiv.org/abs/2506.18831}{Steering Token Usage with PID Control}} \hfill \textbf{Jun 2025}\\
\textit{Lead Investigator} — Introduced redundancy-aware steering method that improved reasoning efficiency and reduced token usage.

\textbf{\href{https://arxiv.org/html/2412.04537}{Understanding Hidden Computations in Transformer Language Models}} \hfill \textbf{Aug 2024}\\
\textit{Lead Investigator} — Explored how transformer internals encode multi-step reasoning in chain-of-thought tasks.

\section{Awards \& Recognition}
\textbf{Winner – AI Alignment Awards} \hfill \textbf{Jul 2023}\\
Recognized among 118 global entries for work on goal misgeneralization and AI safety evaluation.

\textbf{Honorable Mention – Eliciting Latent Knowledge (ARC)} \hfill \textbf{Mar 2022}\\
Acknowledged for novel solutions in latent knowledge elicitation.

\textbf{Bronze Medal – Build-on-Redis Hackathon} \hfill \textbf{Feb 2021}\\
Developed private code search using CodeBERT embeddings and Redis Stack.

\textbf{Excellence Awards (8×) – MuSigma Business Solutions} \hfill \textbf{2019–2024}

\section{Education}
\textbf{Bachelor of Technology – Electronics and Communications Engineering} \hfill \textbf{2015–2019}\\
GMR Institute of Technology, Andhra Pradesh

\end{document}

